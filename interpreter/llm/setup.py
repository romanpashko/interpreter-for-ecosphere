"""
For --local, if a model isn't set,
show downloaded models
and add an option "Download more"
if no downloaded models, just automatically download

return an llm object which will return "messages" and "code" in a stream
"""